{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>full_content</th>\n",
       "      <th>relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89541</td>\n",
       "      <td>International Business Times</td>\n",
       "      <td>UN Chief Urges World To 'Stop The Madness' Of ...</td>\n",
       "      <td>UN Secretary-General Antonio Guterres urged th...</td>\n",
       "      <td>UN Secretary-General Antonio Guterres urged th...</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>UN Secretary-General Antonio Guterres urged th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89542</td>\n",
       "      <td>Prtimes.jp</td>\n",
       "      <td>RANDEBOOよりワンランク上の大人っぽさが漂うニットとベストが新登場。</td>\n",
       "      <td>[株式会社Ainer]\\nRANDEBOO（ランデブー）では2023年7月18日(火)より公...</td>\n",
       "      <td>RANDEBOO2023718()WEB2023 Autumn Winter \\n\"Nepa...</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89543</td>\n",
       "      <td>VOA News</td>\n",
       "      <td>UN Chief Urges World to 'Stop the Madness' of ...</td>\n",
       "      <td>UN Secretary-General Antonio Guterres urged th...</td>\n",
       "      <td>Kathmandu, Nepal  UN Secretary-General Antonio...</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89545</td>\n",
       "      <td>The Indian Express</td>\n",
       "      <td>Sikkim warning: Hydroelectricity push must be ...</td>\n",
       "      <td>Ecologists caution against the adverse effects...</td>\n",
       "      <td>At least 14 persons lost their lives and more ...</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>At least 14 persons lost their lives and more ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89547</td>\n",
       "      <td>The Times of Israel</td>\n",
       "      <td>200 foreigners, dual nationals cut down in Ham...</td>\n",
       "      <td>France lost 35 citizens, Thailand 33, US 31, U...</td>\n",
       "      <td>Scores of foreign citizens were killed, taken ...</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105370</th>\n",
       "      <td>781108</td>\n",
       "      <td>The Indian Express</td>\n",
       "      <td>Have done no wrong, only did party work, says ...</td>\n",
       "      <td>The High Court today allowed Shivakumar to wit...</td>\n",
       "      <td>Karnataka Deputy Chief Minister D K Shivakumar...</td>\n",
       "      <td>Home</td>\n",
       "      <td>Karnataka Deputy Chief Minister D K Shivakumar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105371</th>\n",
       "      <td>781129</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>FC Barcelona Guarantees $77.6 Million Champion...</td>\n",
       "      <td>FC Barcelona have guaranteed at least $77.6 mi...</td>\n",
       "      <td>FC Barcelona have guaranteed at least $767.6 m...</td>\n",
       "      <td>Home</td>\n",
       "      <td>FC Barcelona have guaranteed at least $767.6 m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105372</th>\n",
       "      <td>781235</td>\n",
       "      <td>NPR</td>\n",
       "      <td>Three hospitals ignored her gravely ill fiancé...</td>\n",
       "      <td>Forty years ago, Sarah Lubarsky came home from...</td>\n",
       "      <td>The photo from David and Sarah Lubarsky's wedd...</td>\n",
       "      <td>Home</td>\n",
       "      <td>The photo from David and Sarah Lubarsky's wedd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105373</th>\n",
       "      <td>781240</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>Kerber’s Farm: Bringing Farm To Table To Manha...</td>\n",
       "      <td>A farmstand in Long Island, Kerber’s Farms has...</td>\n",
       "      <td>Kerbers Farm: Bringing Farm To Table To Manhat...</td>\n",
       "      <td>Home</td>\n",
       "      <td>Kerber’s Farm: Bringing Farm To Table To Manha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105374</th>\n",
       "      <td>781308</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>Tips For Investing In Short-Term Rentals In Dubai</td>\n",
       "      <td>By exploring your options and keeping a few be...</td>\n",
       "      <td>Cofounder at UpperKey. Passionate about proper...</td>\n",
       "      <td>Home</td>\n",
       "      <td>Cofounder at UpperKey. Passionate about proper...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105375 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id                   source_name  \\\n",
       "0            89541  International Business Times   \n",
       "1            89542                    Prtimes.jp   \n",
       "2            89543                      VOA News   \n",
       "3            89545            The Indian Express   \n",
       "4            89547           The Times of Israel   \n",
       "...            ...                           ...   \n",
       "105370      781108            The Indian Express   \n",
       "105371      781129                        Forbes   \n",
       "105372      781235                           NPR   \n",
       "105373      781240                        Forbes   \n",
       "105374      781308                        Forbes   \n",
       "\n",
       "                                                    title  \\\n",
       "0       UN Chief Urges World To 'Stop The Madness' Of ...   \n",
       "1                   RANDEBOOよりワンランク上の大人っぽさが漂うニットとベストが新登場。   \n",
       "2       UN Chief Urges World to 'Stop the Madness' of ...   \n",
       "3       Sikkim warning: Hydroelectricity push must be ...   \n",
       "4       200 foreigners, dual nationals cut down in Ham...   \n",
       "...                                                   ...   \n",
       "105370  Have done no wrong, only did party work, says ...   \n",
       "105371  FC Barcelona Guarantees $77.6 Million Champion...   \n",
       "105372  Three hospitals ignored her gravely ill fiancé...   \n",
       "105373  Kerber’s Farm: Bringing Farm To Table To Manha...   \n",
       "105374  Tips For Investing In Short-Term Rentals In Dubai   \n",
       "\n",
       "                                              description  \\\n",
       "0       UN Secretary-General Antonio Guterres urged th...   \n",
       "1       [株式会社Ainer]\\nRANDEBOO（ランデブー）では2023年7月18日(火)より公...   \n",
       "2       UN Secretary-General Antonio Guterres urged th...   \n",
       "3       Ecologists caution against the adverse effects...   \n",
       "4       France lost 35 citizens, Thailand 33, US 31, U...   \n",
       "...                                                   ...   \n",
       "105370  The High Court today allowed Shivakumar to wit...   \n",
       "105371  FC Barcelona have guaranteed at least $77.6 mi...   \n",
       "105372  Forty years ago, Sarah Lubarsky came home from...   \n",
       "105373  A farmstand in Long Island, Kerber’s Farms has...   \n",
       "105374  By exploring your options and keeping a few be...   \n",
       "\n",
       "                                                  content category  \\\n",
       "0       UN Secretary-General Antonio Guterres urged th...    Nepal   \n",
       "1       RANDEBOO2023718()WEB2023 Autumn Winter \\n\"Nepa...    Nepal   \n",
       "2       Kathmandu, Nepal  UN Secretary-General Antonio...    Nepal   \n",
       "3       At least 14 persons lost their lives and more ...    Nepal   \n",
       "4       Scores of foreign citizens were killed, taken ...    Nepal   \n",
       "...                                                   ...      ...   \n",
       "105370  Karnataka Deputy Chief Minister D K Shivakumar...     Home   \n",
       "105371  FC Barcelona have guaranteed at least $767.6 m...     Home   \n",
       "105372  The photo from David and Sarah Lubarsky's wedd...     Home   \n",
       "105373  Kerbers Farm: Bringing Farm To Table To Manhat...     Home   \n",
       "105374  Cofounder at UpperKey. Passionate about proper...     Home   \n",
       "\n",
       "                                             full_content  relevant  \n",
       "0       UN Secretary-General Antonio Guterres urged th...         0  \n",
       "1                                                     NaN         0  \n",
       "2                                                     NaN         0  \n",
       "3       At least 14 persons lost their lives and more ...         0  \n",
       "4                                                     NaN         0  \n",
       "...                                                   ...       ...  \n",
       "105370  Karnataka Deputy Chief Minister D K Shivakumar...         0  \n",
       "105371  FC Barcelona have guaranteed at least $767.6 m...         0  \n",
       "105372  The photo from David and Sarah Lubarsky's wedd...         0  \n",
       "105373  Kerber’s Farm: Bringing Farm To Table To Manha...         0  \n",
       "105374  Cofounder at UpperKey. Passionate about proper...         0  \n",
       "\n",
       "[105375 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = 'C:\\\\Users\\\\tanxe\\\\Programming\\\\ML\\\\WORK\\\\classifier\\\\data.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.drop(columns=['source_id', 'author', 'published_at', 'url_to_image', 'url' ])\n",
    "filtered_df = df\n",
    "filtered_df['relevant'] = filtered_df['category'].apply(lambda x: 1 if x == 'Stock' or x == 'Finance' else 0)\n",
    "df_cleaned = filtered_df.dropna(subset=['content'])\n",
    "balanced_df = df_cleaned\n",
    "balanced_df\n",
    "\n",
    "# filtered_df = df[df['source_name'].isin(['GlobeNewswire', 'The Times of India'])]\n",
    "\n",
    "# filtered_df['relevant'] = filtered_df['category'].apply(lambda x: 1 if x == 'COVID' else 0)\n",
    "# df_cleaned = filtered_df.dropna(subset=['full_content'])\n",
    "# df_relevant_zero = df_cleaned[df_cleaned['relevant'] == 0]\n",
    "# df_relevant_one = df_cleaned[df_cleaned['relevant'] == 1]\n",
    "# df_sampled = df_relevant_zero.sample(n=1400, random_state=42)\n",
    "# balanced_df = pd.concat([df_sampled, df_relevant_one], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanxe\\AppData\\Local\\Temp\\ipykernel_7072\\2424080986.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  balanced_df_24k['relevant'] = balanced_df_24k['category'].apply(lambda x: 1 if x == 'Stock' else 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "relevant\n",
       "0    20757\n",
       "1     3503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_24k = balanced_df[balanced_df['source_name'].isin([\"ETF Daily News\", \"The Times of India\"])]\n",
    "balanced_df_24k['relevant'] = balanced_df_24k['category'].apply(lambda x: 1 if x == 'Stock' else 0)\n",
    "balanced_df_24k = balanced_df_24k.dropna(subset=['content'])\n",
    "balanced_df_24k['relevant'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporating NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanxe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\tanxe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "text = balanced_df['full_content'][0]\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "# nlp = spacy.load('en_core_web_trf') may be better in the office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = balanced_df['full_content'][0]\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UN ORG\n",
      "Antonio Guterres PERSON\n",
      "Monday DATE\n",
      "Himalayan NORP\n",
      "Guterres PERSON\n",
      "Everest LOC\n",
      "Nepal GPE\n",
      "nearly a third CARDINAL\n",
      "just over three decades DATE\n",
      "Himalayas LOC\n",
      "Nepal GPE\n",
      "65 percent PERCENT\n",
      "the last decade DATE\n",
      "Guterres PERSON\n",
      "four-day DATE\n",
      "Nepal GPE\n",
      "Himalayan NORP\n",
      "Hindu NORP\n",
      "around 240 million CARDINAL\n",
      "1.65 billion CARDINAL\n",
      "South Asian NORP\n",
      "Southeast Asian NORP\n",
      "10 CARDINAL\n",
      "Ganges NORP\n",
      "Indus GPE\n",
      "Yellow GPE\n",
      "Mekong GPE\n",
      "Irrawaddy GPE\n",
      "billions CARDINAL\n",
      "today DATE\n",
      "Guterres PERSON\n",
      "Syangboche village GPE\n",
      "Everest LOC\n",
      "nearly 1.2 degrees Celsius QUANTITY\n",
      "the mid-1800s DATE\n",
      "1.5 degrees QUANTITY\n",
      "Guterres PERSON\n",
      "first ORDINAL\n",
      "Himalayan NORP\n",
      "Indus GPE\n",
      "Ganges ORG\n",
      "Brahmaputra ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a seperate column for the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12                                    Taj Mahal_384 2nd_391\n",
       "75                                                India_384\n",
       "76               Offbeat Himachal getaways_384 Dussehra_380\n",
       "126       first_396 Israel_384 Kathmandu_384 the wee hou...\n",
       "128                             Indian_381 the next day_391\n",
       "                                ...                        \n",
       "105352    BRYN MAWR TRUST Co_383 TE Connectivity Ltd._38...\n",
       "105353    AngloGold Ashanti plc_383 NYSE_383 3.8%_393 Mo...\n",
       "105357    Malaga_384 Nov 29_391 2023_391 Europe_385 Wedn...\n",
       "105359    Pharming Group_383 Get Free Report_387 Monday_...\n",
       "105360    Aquis Exchange_383 Canaccord Genuity Group_383...\n",
       "Name: entities, Length: 24260, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities_plus_labels = [f\"{ent}_{ent.label}\" for ent in doc.ents]\n",
    "    return \" \".join(entities_plus_labels)\n",
    "\n",
    "\n",
    "balanced_df_24k['entities'] = balanced_df_24k['content'].apply(extract_entities)\n",
    "balanced_df_24k['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>full_content</th>\n",
       "      <th>relevant</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>94343</td>\n",
       "      <td>The Times of India</td>\n",
       "      <td>These 9 commodity stocks hit 52-week high on T...</td>\n",
       "      <td>During Thursday's trading session, the Sensex ...</td>\n",
       "      <td>Nov 02, 2023, 07:22:41 PM IST\\nDuring Thursday...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Nov 02_391 2023_391 07:22:41 PM_392 Thursday_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57910</th>\n",
       "      <td>133924</td>\n",
       "      <td>The Times of India</td>\n",
       "      <td>Fundamental Radar: Varun Beverages poised to b...</td>\n",
       "      <td>Varun Beverages Ltd is the second-largest fran...</td>\n",
       "      <td>SynopsisVarun Beverages Ltd is the second-larg...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>SynopsisVarun Beverages Ltd_383 second_396 Pep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57935</th>\n",
       "      <td>134021</td>\n",
       "      <td>The Times of India</td>\n",
       "      <td>Stock market update: Mining stocks up as marke...</td>\n",
       "      <td>The 30-share BSE Sensex was  up  425.32 points...</td>\n",
       "      <td>NEW DELHI: Mining stocks were trading higher o...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>Getty Images Nifty moved in a tight range of 8...</td>\n",
       "      <td>1</td>\n",
       "      <td>NEW DELHI_384 Friday_391 10:09AM_397 Oriental_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57936</th>\n",
       "      <td>134022</td>\n",
       "      <td>The Times of India</td>\n",
       "      <td>Stock market update: Fertilisers stocks up as ...</td>\n",
       "      <td>The 30-share BSE Sensex was  up  441.31 points...</td>\n",
       "      <td>NEW DELHI: Fertilisers stocks were trading hig...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>Getty Images NEW DELHI: Fertilisers stocks wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>NEW DELHI_384 Fertilisers_380 Friday_391 Bohra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57937</th>\n",
       "      <td>134023</td>\n",
       "      <td>The Times of India</td>\n",
       "      <td>InterGlobe stock price up 0.08 per cent as Sen...</td>\n",
       "      <td>As of 30-Sep-2023, promoters held 38.02 per ce...</td>\n",
       "      <td>Shares of InterGlobe Aviation Ltd. rose 0.08 p...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>Reuters On an immediate basis, 15,770/52,500 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>InterGlobe Aviation Ltd._383 0.08 per cent_394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102076</th>\n",
       "      <td>693939</td>\n",
       "      <td>ETF Daily News</td>\n",
       "      <td>Universal (NYSE:UVV) vs. British American Toba...</td>\n",
       "      <td>Universal (NYSE:UVV – Get Free Report) and Bri...</td>\n",
       "      <td>Universal (NYSE:UVV – Get Free Report) and Bri...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>Universal (NYSE:UVV–Get Free Report) and Briti...</td>\n",
       "      <td>1</td>\n",
       "      <td>NYSE_383 UVV_383 British American Tobacco_383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102077</th>\n",
       "      <td>693944</td>\n",
       "      <td>The Times of India</td>\n",
       "      <td>Do we have enough retail money in debt markets?</td>\n",
       "      <td>​​For example, as per the monthly data release...</td>\n",
       "      <td>Generally, the retail investors are late to th...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>IANS INSIGHTS  \\n    \\t                    Rea...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102078</th>\n",
       "      <td>693947</td>\n",
       "      <td>The Times of India</td>\n",
       "      <td>FII action, OPEC+ meet among top 10 factors to...</td>\n",
       "      <td>Meena expects the market to experience some di...</td>\n",
       "      <td>Indian frontline indices S&amp;amp;P BSE Sensex an...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>ETMarkets.com Indian frontline indices S&amp;P BSE...</td>\n",
       "      <td>1</td>\n",
       "      <td>Indian_381 BSE Sensex_383 Nifty50_383 Friday_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102079</th>\n",
       "      <td>693954</td>\n",
       "      <td>The Times of India</td>\n",
       "      <td>For workers at this iPhone plant, Tata means a...</td>\n",
       "      <td>At the Narasapura facility, the recent takeove...</td>\n",
       "      <td>It is the Tata tag we aim for, who doesnt want...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>“It is the  Tata  tag we aim for, who doesn’t ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tata_383 Tata_383 iPhone_383 Narasapura_384 Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102820</th>\n",
       "      <td>711912</td>\n",
       "      <td>The Times of India</td>\n",
       "      <td>Riding on the digitization of Indian capital m...</td>\n",
       "      <td>\"The BSE derivatives market share jumped to 14...</td>\n",
       "      <td>Stating Indian exchanges are benefiting from f...</td>\n",
       "      <td>Stock</td>\n",
       "      <td>Reuters Bombay Stock Exchange Related FII acti...</td>\n",
       "      <td>1</td>\n",
       "      <td>Indian_381 innovations &amp;amp_383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3503 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id         source_name  \\\n",
       "3109         94343  The Times of India   \n",
       "57910       133924  The Times of India   \n",
       "57935       134021  The Times of India   \n",
       "57936       134022  The Times of India   \n",
       "57937       134023  The Times of India   \n",
       "...            ...                 ...   \n",
       "102076      693939      ETF Daily News   \n",
       "102077      693944  The Times of India   \n",
       "102078      693947  The Times of India   \n",
       "102079      693954  The Times of India   \n",
       "102820      711912  The Times of India   \n",
       "\n",
       "                                                    title  \\\n",
       "3109    These 9 commodity stocks hit 52-week high on T...   \n",
       "57910   Fundamental Radar: Varun Beverages poised to b...   \n",
       "57935   Stock market update: Mining stocks up as marke...   \n",
       "57936   Stock market update: Fertilisers stocks up as ...   \n",
       "57937   InterGlobe stock price up 0.08 per cent as Sen...   \n",
       "...                                                   ...   \n",
       "102076  Universal (NYSE:UVV) vs. British American Toba...   \n",
       "102077    Do we have enough retail money in debt markets?   \n",
       "102078  FII action, OPEC+ meet among top 10 factors to...   \n",
       "102079  For workers at this iPhone plant, Tata means a...   \n",
       "102820  Riding on the digitization of Indian capital m...   \n",
       "\n",
       "                                              description  \\\n",
       "3109    During Thursday's trading session, the Sensex ...   \n",
       "57910   Varun Beverages Ltd is the second-largest fran...   \n",
       "57935   The 30-share BSE Sensex was  up  425.32 points...   \n",
       "57936   The 30-share BSE Sensex was  up  441.31 points...   \n",
       "57937   As of 30-Sep-2023, promoters held 38.02 per ce...   \n",
       "...                                                   ...   \n",
       "102076  Universal (NYSE:UVV – Get Free Report) and Bri...   \n",
       "102077  ​​For example, as per the monthly data release...   \n",
       "102078  Meena expects the market to experience some di...   \n",
       "102079  At the Narasapura facility, the recent takeove...   \n",
       "102820  \"The BSE derivatives market share jumped to 14...   \n",
       "\n",
       "                                                  content category  \\\n",
       "3109    Nov 02, 2023, 07:22:41 PM IST\\nDuring Thursday...    Stock   \n",
       "57910   SynopsisVarun Beverages Ltd is the second-larg...    Stock   \n",
       "57935   NEW DELHI: Mining stocks were trading higher o...    Stock   \n",
       "57936   NEW DELHI: Fertilisers stocks were trading hig...    Stock   \n",
       "57937   Shares of InterGlobe Aviation Ltd. rose 0.08 p...    Stock   \n",
       "...                                                   ...      ...   \n",
       "102076  Universal (NYSE:UVV – Get Free Report) and Bri...    Stock   \n",
       "102077  Generally, the retail investors are late to th...    Stock   \n",
       "102078  Indian frontline indices S&amp;P BSE Sensex an...    Stock   \n",
       "102079  It is the Tata tag we aim for, who doesnt want...    Stock   \n",
       "102820  Stating Indian exchanges are benefiting from f...    Stock   \n",
       "\n",
       "                                             full_content  relevant  \\\n",
       "3109                                                  NaN         1   \n",
       "57910                                                 NaN         1   \n",
       "57935   Getty Images Nifty moved in a tight range of 8...         1   \n",
       "57936   Getty Images NEW DELHI: Fertilisers stocks wer...         1   \n",
       "57937   Reuters On an immediate basis, 15,770/52,500 a...         1   \n",
       "...                                                   ...       ...   \n",
       "102076  Universal (NYSE:UVV–Get Free Report) and Briti...         1   \n",
       "102077  IANS INSIGHTS  \\n    \\t                    Rea...         1   \n",
       "102078  ETMarkets.com Indian frontline indices S&P BSE...         1   \n",
       "102079  “It is the  Tata  tag we aim for, who doesn’t ...         1   \n",
       "102820  Reuters Bombay Stock Exchange Related FII acti...         1   \n",
       "\n",
       "                                                 entities  \n",
       "3109    Nov 02_391 2023_391 07:22:41 PM_392 Thursday_3...  \n",
       "57910   SynopsisVarun Beverages Ltd_383 second_396 Pep...  \n",
       "57935   NEW DELHI_384 Friday_391 10:09AM_397 Oriental_...  \n",
       "57936   NEW DELHI_384 Fertilisers_380 Friday_391 Bohra...  \n",
       "57937   InterGlobe Aviation Ltd._383 0.08 per cent_394...  \n",
       "...                                                   ...  \n",
       "102076      NYSE_383 UVV_383 British American Tobacco_383  \n",
       "102077                                                     \n",
       "102078  Indian_381 BSE Sensex_383 Nifty50_383 Friday_3...  \n",
       "102079  Tata_383 Tata_383 iPhone_383 Narasapura_384 Ka...  \n",
       "102820                    Indian_381 innovations &amp_383  \n",
       "\n",
       "[3503 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df_24k[balanced_df_24k['relevant'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevant\n",
       "0    12454\n",
       "1     2102\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(balanced_df_24k, test_size=0.4, random_state=42, stratify=balanced_df_24k['relevant'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['relevant'])\n",
    "\n",
    "train_df['relevant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted XLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # This should return True if CUDA is available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted XLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\tanxe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     76\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 78\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m batch_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tanxe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanxe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers import XLNetForSequenceClassification\n",
    "\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        encoding = self.tokenizer(\n",
    "            row['content'], # Replace 'content' with 'article_content' if working with real data\n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            max_length=self.max_length, \n",
    "            return_tensors='pt' #  return the output in the form of PyTorch tensors\n",
    "            )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(row['relevant'], dtype=torch.float), # for BCEWithLogitsLoss use float\n",
    "        }\n",
    "\n",
    "train_dataset = TextDataset(train_df, tokenizer, max_length=128)\n",
    "val_dataset = TextDataset(val_df, tokenizer, max_length=128)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_df['relevant']), y=train_df['relevant'])\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# load the XLNet model\n",
    "XLNet_model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=1)\n",
    "XLNet_model.to(device)\n",
    "\n",
    "# load from checkpoint\n",
    "checkpoint = torch.load('best_XLNet_model_epoch_3_BCEWithLogitsLoss.pt')\n",
    "XLNet_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Loss function and optimizer\n",
    "# loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
    "optimizer = AdamW(XLNet_model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "current_epoch = 5\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(current_epoch, num_epochs):\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    XLNet_model.train() #switch to training mode\n",
    "    train_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad() # Clear old gradients\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "            'labels': batch['labels'].to(device),\n",
    "        }\n",
    "\n",
    "        outputs = XLNet_model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0 or batch_idx == len(train_dataloader) - 1:\n",
    "            print(f\"  Batch {batch_idx + 1}/{len(train_dataloader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(train_dataloader) # average training loss\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    XLNet_model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            inputs = {\n",
    "                'input_ids': batch['input_ids'].to(device),\n",
    "                'attention_mask': batch['attention_mask'].to(device),\n",
    "                'labels': batch['labels'].to(device),\n",
    "            }\n",
    "            outputs = XLNet_model(**inputs)\n",
    "            val_loss += outputs.loss.item()\n",
    "            logits = outputs.logits\n",
    "            preds = torch.sigmoid(logits).cpu().numpy() > 0.5  # threshold = 0.5 for  now\n",
    "            val_preds.extend(preds)           \n",
    "            val_labels.extend(inputs['labels'].cpu().numpy())\n",
    "            \n",
    "    val_loss /= len(val_dataloader) # average validation loss\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(classification_report(val_labels, val_preds))\n",
    "\n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f\"Validation loss improved. Saving model.\")\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': XLNet_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_val_loss': best_val_loss\n",
    "    }, f\"best_XLNet_model_epoch_{epoch}_BCEWithLogitsLoss.pt\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted XLNet\n",
    "incorporating entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  Batch 10/910 - Loss: 0.1541\n",
      "  Batch 20/910 - Loss: 0.1619\n",
      "  Batch 30/910 - Loss: 0.1666\n",
      "  Batch 40/910 - Loss: 0.1740\n",
      "  Batch 50/910 - Loss: 0.3635\n",
      "  Batch 60/910 - Loss: 0.1165\n",
      "  Batch 70/910 - Loss: 0.1704\n",
      "  Batch 80/910 - Loss: 0.0912\n",
      "  Batch 90/910 - Loss: 0.1198\n",
      "  Batch 100/910 - Loss: 0.0579\n",
      "  Batch 110/910 - Loss: 0.1315\n",
      "  Batch 120/910 - Loss: 0.0964\n",
      "  Batch 130/910 - Loss: 0.2112\n",
      "  Batch 140/910 - Loss: 0.1756\n",
      "  Batch 150/910 - Loss: 0.0573\n",
      "  Batch 160/910 - Loss: 0.1347\n",
      "  Batch 170/910 - Loss: 0.0973\n",
      "  Batch 180/910 - Loss: 0.1143\n",
      "  Batch 190/910 - Loss: 0.1210\n",
      "  Batch 200/910 - Loss: 0.0596\n",
      "  Batch 210/910 - Loss: 0.1602\n",
      "  Batch 220/910 - Loss: 0.1264\n",
      "  Batch 230/910 - Loss: 0.0884\n",
      "  Batch 240/910 - Loss: 0.0350\n",
      "  Batch 250/910 - Loss: 0.2496\n",
      "  Batch 260/910 - Loss: 0.0920\n",
      "  Batch 270/910 - Loss: 0.1129\n",
      "  Batch 280/910 - Loss: 0.0786\n",
      "  Batch 290/910 - Loss: 0.0545\n",
      "  Batch 300/910 - Loss: 0.0738\n",
      "  Batch 310/910 - Loss: 0.0559\n",
      "  Batch 320/910 - Loss: 0.0525\n",
      "  Batch 330/910 - Loss: 0.0473\n",
      "  Batch 340/910 - Loss: 0.1325\n",
      "  Batch 350/910 - Loss: 0.1020\n",
      "  Batch 360/910 - Loss: 0.1042\n",
      "  Batch 370/910 - Loss: 0.0413\n",
      "  Batch 380/910 - Loss: 0.0410\n",
      "  Batch 390/910 - Loss: 0.2188\n",
      "  Batch 400/910 - Loss: 0.0555\n",
      "  Batch 410/910 - Loss: 0.1838\n",
      "  Batch 420/910 - Loss: 0.1628\n",
      "  Batch 430/910 - Loss: 0.0900\n",
      "  Batch 440/910 - Loss: 0.0372\n",
      "  Batch 450/910 - Loss: 0.0927\n",
      "  Batch 460/910 - Loss: 0.0808\n",
      "  Batch 470/910 - Loss: 0.1703\n",
      "  Batch 480/910 - Loss: 0.1626\n",
      "  Batch 490/910 - Loss: 0.0707\n",
      "  Batch 500/910 - Loss: 0.0612\n",
      "  Batch 510/910 - Loss: 0.0197\n",
      "  Batch 520/910 - Loss: 0.0241\n",
      "  Batch 530/910 - Loss: 0.0812\n",
      "  Batch 540/910 - Loss: 0.0907\n",
      "  Batch 550/910 - Loss: 0.1068\n",
      "  Batch 560/910 - Loss: 0.0671\n",
      "  Batch 570/910 - Loss: 0.0558\n",
      "  Batch 580/910 - Loss: 0.1547\n",
      "  Batch 590/910 - Loss: 0.0395\n",
      "  Batch 600/910 - Loss: 0.0142\n",
      "  Batch 610/910 - Loss: 0.1714\n",
      "  Batch 620/910 - Loss: 0.1030\n",
      "  Batch 630/910 - Loss: 0.1052\n",
      "  Batch 640/910 - Loss: 0.0208\n",
      "  Batch 650/910 - Loss: 0.0320\n",
      "  Batch 660/910 - Loss: 0.0621\n",
      "  Batch 670/910 - Loss: 0.0371\n",
      "  Batch 680/910 - Loss: 0.0743\n",
      "  Batch 690/910 - Loss: 0.0354\n",
      "  Batch 700/910 - Loss: 0.0535\n",
      "  Batch 710/910 - Loss: 0.0058\n",
      "  Batch 720/910 - Loss: 0.1074\n",
      "  Batch 730/910 - Loss: 0.0613\n",
      "  Batch 740/910 - Loss: 0.1209\n",
      "  Batch 750/910 - Loss: 0.1203\n",
      "  Batch 760/910 - Loss: 0.0856\n",
      "  Batch 770/910 - Loss: 0.1318\n",
      "  Batch 780/910 - Loss: 0.0800\n",
      "  Batch 790/910 - Loss: 0.1060\n",
      "  Batch 800/910 - Loss: 0.0509\n",
      "  Batch 810/910 - Loss: 0.0827\n",
      "  Batch 820/910 - Loss: 0.0967\n",
      "  Batch 830/910 - Loss: 0.0947\n",
      "  Batch 840/910 - Loss: 0.0416\n",
      "  Batch 850/910 - Loss: 0.1368\n",
      "  Batch 860/910 - Loss: 0.0764\n",
      "  Batch 870/910 - Loss: 0.0333\n",
      "  Batch 880/910 - Loss: 0.1003\n",
      "  Batch 890/910 - Loss: 0.1318\n",
      "  Batch 900/910 - Loss: 0.0852\n",
      "  Batch 910/910 - Loss: 0.0389\n",
      "Training Loss: 0.1012\n",
      "Validation Loss: 0.0788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.69      0.81      4151\n",
      "         1.0       0.34      0.94      0.50       701\n",
      "\n",
      "    accuracy                           0.72      4852\n",
      "   macro avg       0.66      0.81      0.65      4852\n",
      "weighted avg       0.89      0.72      0.76      4852\n",
      "\n",
      "Validation loss improved. Saving model.\n",
      "Epoch 2/20\n",
      "  Batch 10/910 - Loss: 0.0830\n",
      "  Batch 20/910 - Loss: 0.0765\n",
      "  Batch 30/910 - Loss: 0.0594\n",
      "  Batch 40/910 - Loss: 0.1139\n",
      "  Batch 50/910 - Loss: 0.1603\n",
      "  Batch 60/910 - Loss: 0.0800\n",
      "  Batch 70/910 - Loss: 0.0963\n",
      "  Batch 80/910 - Loss: 0.1681\n",
      "  Batch 90/910 - Loss: 0.0843\n",
      "  Batch 100/910 - Loss: 0.0129\n",
      "  Batch 110/910 - Loss: 0.0850\n",
      "  Batch 120/910 - Loss: 0.0126\n",
      "  Batch 130/910 - Loss: 0.0686\n",
      "  Batch 140/910 - Loss: 0.1215\n",
      "  Batch 150/910 - Loss: 0.0491\n",
      "  Batch 160/910 - Loss: 0.0602\n",
      "  Batch 170/910 - Loss: 0.0609\n",
      "  Batch 180/910 - Loss: 0.0579\n",
      "  Batch 190/910 - Loss: 0.0493\n",
      "  Batch 200/910 - Loss: 0.0267\n",
      "  Batch 210/910 - Loss: 0.0601\n",
      "  Batch 220/910 - Loss: 0.1160\n",
      "  Batch 230/910 - Loss: 0.1169\n",
      "  Batch 240/910 - Loss: 0.1225\n",
      "  Batch 250/910 - Loss: 0.1280\n",
      "  Batch 260/910 - Loss: 0.0221\n",
      "  Batch 270/910 - Loss: 0.0707\n",
      "  Batch 280/910 - Loss: 0.0313\n",
      "  Batch 290/910 - Loss: 0.1603\n",
      "  Batch 300/910 - Loss: 0.0506\n",
      "  Batch 310/910 - Loss: 0.0888\n",
      "  Batch 320/910 - Loss: 0.0810\n",
      "  Batch 330/910 - Loss: 0.0800\n",
      "  Batch 340/910 - Loss: 0.0970\n",
      "  Batch 350/910 - Loss: 0.1530\n",
      "  Batch 360/910 - Loss: 0.0614\n",
      "  Batch 370/910 - Loss: 0.0105\n",
      "  Batch 380/910 - Loss: 0.0451\n",
      "  Batch 390/910 - Loss: 0.0353\n",
      "  Batch 400/910 - Loss: 0.1077\n",
      "  Batch 410/910 - Loss: 0.0381\n",
      "  Batch 420/910 - Loss: 0.0416\n",
      "  Batch 430/910 - Loss: 0.0343\n",
      "  Batch 440/910 - Loss: 0.0364\n",
      "  Batch 450/910 - Loss: 0.0545\n",
      "  Batch 460/910 - Loss: 0.1255\n",
      "  Batch 470/910 - Loss: 0.0912\n",
      "  Batch 480/910 - Loss: 0.0970\n",
      "  Batch 490/910 - Loss: 0.0108\n",
      "  Batch 500/910 - Loss: 0.2268\n",
      "  Batch 510/910 - Loss: 0.1929\n",
      "  Batch 520/910 - Loss: 0.0686\n",
      "  Batch 530/910 - Loss: 0.0227\n",
      "  Batch 540/910 - Loss: 0.1163\n",
      "  Batch 550/910 - Loss: 0.0665\n",
      "  Batch 560/910 - Loss: 0.0868\n",
      "  Batch 570/910 - Loss: 0.0922\n",
      "  Batch 580/910 - Loss: 0.0272\n",
      "  Batch 590/910 - Loss: 0.0290\n",
      "  Batch 600/910 - Loss: 0.1011\n",
      "  Batch 610/910 - Loss: 0.1339\n",
      "  Batch 620/910 - Loss: 0.1209\n",
      "  Batch 630/910 - Loss: 0.1102\n",
      "  Batch 640/910 - Loss: 0.0789\n",
      "  Batch 650/910 - Loss: 0.0917\n",
      "  Batch 660/910 - Loss: 0.0731\n",
      "  Batch 670/910 - Loss: 0.0595\n",
      "  Batch 680/910 - Loss: 0.1254\n",
      "  Batch 690/910 - Loss: 0.0974\n",
      "  Batch 700/910 - Loss: 0.1065\n",
      "  Batch 710/910 - Loss: 0.1082\n",
      "  Batch 720/910 - Loss: 0.0180\n",
      "  Batch 730/910 - Loss: 0.0702\n",
      "  Batch 740/910 - Loss: 0.1129\n",
      "  Batch 750/910 - Loss: 0.0610\n",
      "  Batch 760/910 - Loss: 0.0328\n",
      "  Batch 770/910 - Loss: 0.0512\n",
      "  Batch 780/910 - Loss: 0.0862\n",
      "  Batch 790/910 - Loss: 0.1084\n",
      "  Batch 800/910 - Loss: 0.0530\n",
      "  Batch 810/910 - Loss: 0.0716\n",
      "  Batch 820/910 - Loss: 0.1591\n",
      "  Batch 830/910 - Loss: 0.1583\n",
      "  Batch 840/910 - Loss: 0.0608\n",
      "  Batch 850/910 - Loss: 0.0893\n",
      "  Batch 860/910 - Loss: 0.0225\n",
      "  Batch 870/910 - Loss: 0.0762\n",
      "  Batch 880/910 - Loss: 0.1808\n",
      "  Batch 890/910 - Loss: 0.0967\n",
      "  Batch 900/910 - Loss: 0.0410\n",
      "  Batch 910/910 - Loss: 0.0462\n",
      "Training Loss: 0.0799\n",
      "Validation Loss: 0.0741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.75      0.85      4151\n",
      "         1.0       0.38      0.94      0.55       701\n",
      "\n",
      "    accuracy                           0.77      4852\n",
      "   macro avg       0.69      0.84      0.70      4852\n",
      "weighted avg       0.90      0.77      0.81      4852\n",
      "\n",
      "Validation loss improved. Saving model.\n",
      "Epoch 3/20\n",
      "  Batch 10/910 - Loss: 0.0531\n",
      "  Batch 20/910 - Loss: 0.0915\n",
      "  Batch 30/910 - Loss: 0.0930\n",
      "  Batch 40/910 - Loss: 0.1131\n",
      "  Batch 50/910 - Loss: 0.0998\n",
      "  Batch 60/910 - Loss: 0.0512\n",
      "  Batch 70/910 - Loss: 0.0179\n",
      "  Batch 80/910 - Loss: 0.0519\n",
      "  Batch 90/910 - Loss: 0.1009\n",
      "  Batch 100/910 - Loss: 0.0895\n",
      "  Batch 110/910 - Loss: 0.0941\n",
      "  Batch 120/910 - Loss: 0.0435\n",
      "  Batch 130/910 - Loss: 0.1156\n",
      "  Batch 140/910 - Loss: 0.0541\n",
      "  Batch 150/910 - Loss: 0.0477\n",
      "  Batch 160/910 - Loss: 0.0069\n",
      "  Batch 170/910 - Loss: 0.1201\n",
      "  Batch 180/910 - Loss: 0.1077\n",
      "  Batch 190/910 - Loss: 0.1410\n",
      "  Batch 200/910 - Loss: 0.0406\n",
      "  Batch 210/910 - Loss: 0.0225\n",
      "  Batch 220/910 - Loss: 0.0779\n",
      "  Batch 230/910 - Loss: 0.0274\n",
      "  Batch 240/910 - Loss: 0.0735\n",
      "  Batch 250/910 - Loss: 0.0399\n",
      "  Batch 260/910 - Loss: 0.0504\n",
      "  Batch 270/910 - Loss: 0.1261\n",
      "  Batch 280/910 - Loss: 0.0414\n",
      "  Batch 290/910 - Loss: 0.0384\n",
      "  Batch 300/910 - Loss: 0.1090\n",
      "  Batch 310/910 - Loss: 0.1597\n",
      "  Batch 320/910 - Loss: 0.0415\n",
      "  Batch 330/910 - Loss: 0.1044\n",
      "  Batch 340/910 - Loss: 0.0090\n",
      "  Batch 350/910 - Loss: 0.1194\n",
      "  Batch 360/910 - Loss: 0.0809\n",
      "  Batch 370/910 - Loss: 0.0788\n",
      "  Batch 380/910 - Loss: 0.0928\n",
      "  Batch 390/910 - Loss: 0.0464\n",
      "  Batch 400/910 - Loss: 0.0169\n",
      "  Batch 410/910 - Loss: 0.1359\n",
      "  Batch 420/910 - Loss: 0.0863\n",
      "  Batch 430/910 - Loss: 0.0956\n",
      "  Batch 440/910 - Loss: 0.0605\n",
      "  Batch 450/910 - Loss: 0.0931\n",
      "  Batch 460/910 - Loss: 0.0361\n",
      "  Batch 470/910 - Loss: 0.0630\n",
      "  Batch 480/910 - Loss: 0.0787\n",
      "  Batch 490/910 - Loss: 0.0106\n",
      "  Batch 500/910 - Loss: 0.1316\n",
      "  Batch 510/910 - Loss: 0.0754\n",
      "  Batch 520/910 - Loss: 0.0917\n",
      "  Batch 530/910 - Loss: 0.0982\n",
      "  Batch 540/910 - Loss: 0.1052\n",
      "  Batch 550/910 - Loss: 0.1235\n",
      "  Batch 560/910 - Loss: 0.0413\n",
      "  Batch 570/910 - Loss: 0.0437\n",
      "  Batch 580/910 - Loss: 0.0725\n",
      "  Batch 590/910 - Loss: 0.0526\n",
      "  Batch 600/910 - Loss: 0.0362\n",
      "  Batch 610/910 - Loss: 0.0076\n",
      "  Batch 620/910 - Loss: 0.0602\n",
      "  Batch 630/910 - Loss: 0.0724\n",
      "  Batch 640/910 - Loss: 0.0145\n",
      "  Batch 650/910 - Loss: 0.1695\n",
      "  Batch 660/910 - Loss: 0.1261\n",
      "  Batch 670/910 - Loss: 0.0667\n",
      "  Batch 680/910 - Loss: 0.1191\n",
      "  Batch 690/910 - Loss: 0.0982\n",
      "  Batch 700/910 - Loss: 0.0374\n",
      "  Batch 710/910 - Loss: 0.1668\n",
      "  Batch 720/910 - Loss: 0.0629\n",
      "  Batch 730/910 - Loss: 0.0972\n",
      "  Batch 740/910 - Loss: 0.0819\n",
      "  Batch 750/910 - Loss: 0.0801\n",
      "  Batch 760/910 - Loss: 0.1570\n",
      "  Batch 770/910 - Loss: 0.0815\n",
      "  Batch 780/910 - Loss: 0.0644\n",
      "  Batch 790/910 - Loss: 0.0204\n",
      "  Batch 800/910 - Loss: 0.0101\n",
      "  Batch 810/910 - Loss: 0.1201\n",
      "  Batch 820/910 - Loss: 0.0463\n",
      "  Batch 830/910 - Loss: 0.1265\n",
      "  Batch 840/910 - Loss: 0.0445\n",
      "  Batch 850/910 - Loss: 0.0255\n",
      "  Batch 860/910 - Loss: 0.1060\n",
      "  Batch 870/910 - Loss: 0.1023\n",
      "  Batch 880/910 - Loss: 0.0477\n",
      "  Batch 890/910 - Loss: 0.1015\n",
      "  Batch 900/910 - Loss: 0.0428\n",
      "  Batch 910/910 - Loss: 0.0493\n",
      "Training Loss: 0.0718\n",
      "Validation Loss: 0.0700\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.01      0.01      4151\n",
      "         1.0       0.15      1.00      0.25       701\n",
      "\n",
      "    accuracy                           0.15      4852\n",
      "   macro avg       0.57      0.50      0.13      4852\n",
      "weighted avg       0.88      0.15      0.05      4852\n",
      "\n",
      "Validation loss improved. Saving model.\n",
      "Epoch 4/20\n",
      "  Batch 10/910 - Loss: 0.0593\n",
      "  Batch 20/910 - Loss: 0.1136\n",
      "  Batch 30/910 - Loss: 0.0786\n",
      "  Batch 40/910 - Loss: 0.0314\n",
      "  Batch 50/910 - Loss: 0.0171\n",
      "  Batch 60/910 - Loss: 0.0270\n",
      "  Batch 70/910 - Loss: 0.0343\n",
      "  Batch 80/910 - Loss: 0.0462\n",
      "  Batch 90/910 - Loss: 0.0293\n",
      "  Batch 100/910 - Loss: 0.0202\n",
      "  Batch 110/910 - Loss: 0.0423\n",
      "  Batch 120/910 - Loss: 0.0601\n",
      "  Batch 130/910 - Loss: 0.0683\n",
      "  Batch 140/910 - Loss: 0.0043\n",
      "  Batch 150/910 - Loss: 0.0683\n",
      "  Batch 160/910 - Loss: 0.0657\n",
      "  Batch 170/910 - Loss: 0.0793\n",
      "  Batch 180/910 - Loss: 0.0536\n",
      "  Batch 190/910 - Loss: 0.0957\n",
      "  Batch 200/910 - Loss: 0.0358\n",
      "  Batch 210/910 - Loss: 0.1001\n",
      "  Batch 220/910 - Loss: 0.0294\n",
      "  Batch 230/910 - Loss: 0.0365\n",
      "  Batch 240/910 - Loss: 0.0477\n",
      "  Batch 250/910 - Loss: 0.0578\n",
      "  Batch 260/910 - Loss: 0.0185\n",
      "  Batch 270/910 - Loss: 0.1107\n",
      "  Batch 280/910 - Loss: 0.0605\n",
      "  Batch 290/910 - Loss: 0.0208\n",
      "  Batch 300/910 - Loss: 0.0857\n",
      "  Batch 310/910 - Loss: 0.0480\n",
      "  Batch 320/910 - Loss: 0.1578\n",
      "  Batch 330/910 - Loss: 0.0491\n",
      "  Batch 340/910 - Loss: 0.0806\n",
      "  Batch 350/910 - Loss: 0.0078\n",
      "  Batch 360/910 - Loss: 0.1041\n",
      "  Batch 370/910 - Loss: 0.0174\n",
      "  Batch 380/910 - Loss: 0.0317\n",
      "  Batch 390/910 - Loss: 0.0626\n",
      "  Batch 400/910 - Loss: 0.0732\n",
      "  Batch 410/910 - Loss: 0.0125\n",
      "  Batch 420/910 - Loss: 0.0290\n",
      "  Batch 430/910 - Loss: 0.1157\n",
      "  Batch 440/910 - Loss: 0.0234\n",
      "  Batch 450/910 - Loss: 0.1183\n",
      "  Batch 460/910 - Loss: 0.0565\n",
      "  Batch 470/910 - Loss: 0.0807\n",
      "  Batch 480/910 - Loss: 0.0717\n",
      "  Batch 490/910 - Loss: 0.0983\n",
      "  Batch 500/910 - Loss: 0.0613\n",
      "  Batch 510/910 - Loss: 0.0645\n",
      "  Batch 520/910 - Loss: 0.0542\n",
      "  Batch 530/910 - Loss: 0.0392\n",
      "  Batch 540/910 - Loss: 0.0076\n",
      "  Batch 550/910 - Loss: 0.0131\n",
      "  Batch 560/910 - Loss: 0.0244\n",
      "  Batch 570/910 - Loss: 0.0097\n",
      "  Batch 580/910 - Loss: 0.0173\n",
      "  Batch 590/910 - Loss: 0.0517\n",
      "  Batch 600/910 - Loss: 0.0676\n",
      "  Batch 610/910 - Loss: 0.0169\n",
      "  Batch 620/910 - Loss: 0.0650\n",
      "  Batch 630/910 - Loss: 0.0295\n",
      "  Batch 640/910 - Loss: 0.1474\n",
      "  Batch 650/910 - Loss: 0.0661\n",
      "  Batch 660/910 - Loss: 0.0602\n",
      "  Batch 670/910 - Loss: 0.1212\n",
      "  Batch 680/910 - Loss: 0.1198\n",
      "  Batch 690/910 - Loss: 0.0563\n",
      "  Batch 700/910 - Loss: 0.0655\n",
      "  Batch 710/910 - Loss: 0.0514\n",
      "  Batch 720/910 - Loss: 0.1025\n",
      "  Batch 730/910 - Loss: 0.0630\n",
      "  Batch 740/910 - Loss: 0.1150\n",
      "  Batch 750/910 - Loss: 0.0219\n",
      "  Batch 760/910 - Loss: 0.0031\n",
      "  Batch 770/910 - Loss: 0.0642\n",
      "  Batch 780/910 - Loss: 0.1115\n",
      "  Batch 790/910 - Loss: 0.1681\n",
      "  Batch 800/910 - Loss: 0.0102\n",
      "  Batch 810/910 - Loss: 0.0061\n",
      "  Batch 820/910 - Loss: 0.0028\n",
      "  Batch 830/910 - Loss: 0.0812\n",
      "  Batch 840/910 - Loss: 0.1708\n",
      "  Batch 850/910 - Loss: 0.0216\n",
      "  Batch 860/910 - Loss: 0.0272\n",
      "  Batch 870/910 - Loss: 0.0824\n",
      "  Batch 880/910 - Loss: 0.0603\n",
      "  Batch 890/910 - Loss: 0.0615\n",
      "  Batch 900/910 - Loss: 0.0314\n",
      "  Batch 910/910 - Loss: 0.0354\n",
      "Training Loss: 0.0589\n",
      "Validation Loss: 0.0726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.75      0.85      4151\n",
      "         1.0       0.39      0.94      0.55       701\n",
      "\n",
      "    accuracy                           0.78      4852\n",
      "   macro avg       0.69      0.85      0.70      4852\n",
      "weighted avg       0.90      0.78      0.81      4852\n",
      "\n",
      "Epoch 5/20\n",
      "  Batch 10/910 - Loss: 0.0357\n",
      "  Batch 20/910 - Loss: 0.0298\n",
      "  Batch 30/910 - Loss: 0.0014\n",
      "  Batch 40/910 - Loss: 0.0288\n",
      "  Batch 50/910 - Loss: 0.0317\n",
      "  Batch 60/910 - Loss: 0.0379\n",
      "  Batch 70/910 - Loss: 0.0055\n",
      "  Batch 80/910 - Loss: 0.0609\n",
      "  Batch 90/910 - Loss: 0.0769\n",
      "  Batch 100/910 - Loss: 0.1176\n",
      "  Batch 110/910 - Loss: 0.0422\n",
      "  Batch 120/910 - Loss: 0.0453\n",
      "  Batch 130/910 - Loss: 0.0555\n",
      "  Batch 140/910 - Loss: 0.1026\n",
      "  Batch 150/910 - Loss: 0.0081\n",
      "  Batch 160/910 - Loss: 0.0768\n",
      "  Batch 170/910 - Loss: 0.0236\n",
      "  Batch 180/910 - Loss: 0.0328\n",
      "  Batch 190/910 - Loss: 0.0063\n",
      "  Batch 200/910 - Loss: 0.0035\n",
      "  Batch 210/910 - Loss: 0.0359\n",
      "  Batch 220/910 - Loss: 0.1808\n",
      "  Batch 230/910 - Loss: 0.0180\n",
      "  Batch 240/910 - Loss: 0.0580\n",
      "  Batch 250/910 - Loss: 0.1510\n",
      "  Batch 260/910 - Loss: 0.0936\n",
      "  Batch 270/910 - Loss: 0.0422\n",
      "  Batch 280/910 - Loss: 0.0257\n",
      "  Batch 290/910 - Loss: 0.0070\n",
      "  Batch 300/910 - Loss: 0.1721\n",
      "  Batch 310/910 - Loss: 0.0371\n",
      "  Batch 320/910 - Loss: 0.1372\n",
      "  Batch 330/910 - Loss: 0.0066\n",
      "  Batch 340/910 - Loss: 0.0130\n",
      "  Batch 350/910 - Loss: 0.0563\n",
      "  Batch 360/910 - Loss: 0.0524\n",
      "  Batch 370/910 - Loss: 0.0566\n",
      "  Batch 380/910 - Loss: 0.0377\n",
      "  Batch 390/910 - Loss: 0.0453\n",
      "  Batch 400/910 - Loss: 0.0208\n",
      "  Batch 410/910 - Loss: 0.0447\n",
      "  Batch 420/910 - Loss: 0.0202\n",
      "  Batch 430/910 - Loss: 0.0041\n",
      "  Batch 440/910 - Loss: 0.0501\n",
      "  Batch 450/910 - Loss: 0.1126\n",
      "  Batch 460/910 - Loss: 0.0641\n",
      "  Batch 470/910 - Loss: 0.0987\n",
      "  Batch 480/910 - Loss: 0.0119\n",
      "  Batch 490/910 - Loss: 0.1470\n",
      "  Batch 500/910 - Loss: 0.0860\n",
      "  Batch 510/910 - Loss: 0.0898\n",
      "  Batch 520/910 - Loss: 0.0481\n",
      "  Batch 530/910 - Loss: 0.0427\n",
      "  Batch 540/910 - Loss: 0.0108\n",
      "  Batch 550/910 - Loss: 0.0698\n",
      "  Batch 560/910 - Loss: 0.1351\n",
      "  Batch 570/910 - Loss: 0.0422\n",
      "  Batch 580/910 - Loss: 0.0208\n",
      "  Batch 590/910 - Loss: 0.0090\n",
      "  Batch 600/910 - Loss: 0.0098\n",
      "  Batch 610/910 - Loss: 0.0056\n",
      "  Batch 620/910 - Loss: 0.0729\n",
      "  Batch 630/910 - Loss: 0.0800\n",
      "  Batch 640/910 - Loss: 0.1234\n",
      "  Batch 650/910 - Loss: 0.1154\n",
      "  Batch 660/910 - Loss: 0.0018\n",
      "  Batch 670/910 - Loss: 0.0406\n",
      "  Batch 680/910 - Loss: 0.1463\n",
      "  Batch 690/910 - Loss: 0.0026\n",
      "  Batch 700/910 - Loss: 0.0102\n",
      "  Batch 710/910 - Loss: 0.0587\n",
      "  Batch 720/910 - Loss: 0.0304\n",
      "  Batch 730/910 - Loss: 0.0955\n",
      "  Batch 740/910 - Loss: 0.0173\n",
      "  Batch 750/910 - Loss: 0.0297\n",
      "  Batch 760/910 - Loss: 0.1061\n",
      "  Batch 770/910 - Loss: 0.0313\n",
      "  Batch 780/910 - Loss: 0.0778\n",
      "  Batch 790/910 - Loss: 0.0294\n",
      "  Batch 800/910 - Loss: 0.0881\n",
      "  Batch 810/910 - Loss: 0.2272\n",
      "  Batch 820/910 - Loss: 0.0667\n",
      "  Batch 830/910 - Loss: 0.0582\n",
      "  Batch 840/910 - Loss: 0.0372\n",
      "  Batch 850/910 - Loss: 0.0199\n",
      "  Batch 860/910 - Loss: 0.0791\n",
      "  Batch 870/910 - Loss: 0.1115\n",
      "  Batch 880/910 - Loss: 0.0089\n",
      "  Batch 890/910 - Loss: 0.0820\n",
      "  Batch 900/910 - Loss: 0.1056\n",
      "  Batch 910/910 - Loss: 0.0077\n",
      "Training Loss: 0.0483\n",
      "Validation Loss: 0.0691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.10      0.19      4151\n",
      "         1.0       0.16      1.00      0.27       701\n",
      "\n",
      "    accuracy                           0.23      4852\n",
      "   macro avg       0.58      0.55      0.23      4852\n",
      "weighted avg       0.88      0.23      0.20      4852\n",
      "\n",
      "Validation loss improved. Saving model.\n",
      "Epoch 6/20\n",
      "  Batch 10/910 - Loss: 0.0446\n",
      "  Batch 20/910 - Loss: 0.1234\n",
      "  Batch 30/910 - Loss: 0.0582\n",
      "  Batch 40/910 - Loss: 0.0661\n",
      "  Batch 50/910 - Loss: 0.0598\n",
      "  Batch 60/910 - Loss: 0.0532\n",
      "  Batch 70/910 - Loss: 0.0317\n",
      "  Batch 80/910 - Loss: 0.0499\n",
      "  Batch 90/910 - Loss: 0.0639\n",
      "  Batch 100/910 - Loss: 0.0084\n",
      "  Batch 110/910 - Loss: 0.0053\n",
      "  Batch 120/910 - Loss: 0.0194\n",
      "  Batch 130/910 - Loss: 0.0175\n",
      "  Batch 140/910 - Loss: 0.0440\n",
      "  Batch 150/910 - Loss: 0.0320\n",
      "  Batch 160/910 - Loss: 0.0702\n",
      "  Batch 170/910 - Loss: 0.0583\n",
      "  Batch 180/910 - Loss: 0.0543\n",
      "  Batch 190/910 - Loss: 0.0174\n",
      "  Batch 200/910 - Loss: 0.0199\n",
      "  Batch 210/910 - Loss: 0.0262\n",
      "  Batch 220/910 - Loss: 0.0822\n",
      "  Batch 230/910 - Loss: 0.0196\n",
      "  Batch 240/910 - Loss: 0.0599\n",
      "  Batch 250/910 - Loss: 0.0103\n",
      "  Batch 260/910 - Loss: 0.0646\n",
      "  Batch 270/910 - Loss: 0.0373\n",
      "  Batch 280/910 - Loss: 0.0674\n",
      "  Batch 290/910 - Loss: 0.0095\n",
      "  Batch 300/910 - Loss: 0.0793\n",
      "  Batch 310/910 - Loss: 0.0345\n",
      "  Batch 320/910 - Loss: 0.1244\n",
      "  Batch 330/910 - Loss: 0.0125\n",
      "  Batch 340/910 - Loss: 0.0128\n",
      "  Batch 350/910 - Loss: 0.0054\n",
      "  Batch 360/910 - Loss: 0.0924\n",
      "  Batch 370/910 - Loss: 0.0223\n",
      "  Batch 380/910 - Loss: 0.0275\n",
      "  Batch 390/910 - Loss: 0.0329\n",
      "  Batch 400/910 - Loss: 0.0190\n",
      "  Batch 410/910 - Loss: 0.0020\n",
      "  Batch 420/910 - Loss: 0.0535\n",
      "  Batch 430/910 - Loss: 0.0252\n",
      "  Batch 440/910 - Loss: 0.0855\n",
      "  Batch 450/910 - Loss: 0.0769\n",
      "  Batch 460/910 - Loss: 0.0864\n",
      "  Batch 470/910 - Loss: 0.0021\n",
      "  Batch 480/910 - Loss: 0.0037\n",
      "  Batch 490/910 - Loss: 0.0700\n",
      "  Batch 500/910 - Loss: 0.0029\n",
      "  Batch 510/910 - Loss: 0.0111\n",
      "  Batch 520/910 - Loss: 0.0959\n",
      "  Batch 530/910 - Loss: 0.0649\n",
      "  Batch 540/910 - Loss: 0.1137\n",
      "  Batch 550/910 - Loss: 0.0731\n",
      "  Batch 560/910 - Loss: 0.0173\n",
      "  Batch 570/910 - Loss: 0.0476\n",
      "  Batch 580/910 - Loss: 0.0059\n",
      "  Batch 590/910 - Loss: 0.0809\n",
      "  Batch 600/910 - Loss: 0.0096\n",
      "  Batch 610/910 - Loss: 0.0283\n",
      "  Batch 620/910 - Loss: 0.0353\n",
      "  Batch 630/910 - Loss: 0.0210\n",
      "  Batch 640/910 - Loss: 0.0039\n",
      "  Batch 650/910 - Loss: 0.0072\n",
      "  Batch 660/910 - Loss: 0.0916\n",
      "  Batch 670/910 - Loss: 0.0095\n",
      "  Batch 680/910 - Loss: 0.1054\n",
      "  Batch 690/910 - Loss: 0.0735\n",
      "  Batch 700/910 - Loss: 0.0572\n",
      "  Batch 710/910 - Loss: 0.0025\n",
      "  Batch 720/910 - Loss: 0.0276\n",
      "  Batch 730/910 - Loss: 0.0133\n",
      "  Batch 740/910 - Loss: 0.0234\n",
      "  Batch 750/910 - Loss: 0.0531\n",
      "  Batch 760/910 - Loss: 0.0009\n",
      "  Batch 770/910 - Loss: 0.0821\n",
      "  Batch 780/910 - Loss: 0.0034\n",
      "  Batch 790/910 - Loss: 0.0016\n",
      "  Batch 800/910 - Loss: 0.0013\n",
      "  Batch 810/910 - Loss: 0.1021\n",
      "  Batch 820/910 - Loss: 0.0241\n",
      "  Batch 830/910 - Loss: 0.0137\n",
      "  Batch 840/910 - Loss: 0.0128\n",
      "  Batch 850/910 - Loss: 0.0258\n",
      "  Batch 860/910 - Loss: 0.0043\n",
      "  Batch 870/910 - Loss: 0.0029\n",
      "  Batch 880/910 - Loss: 0.0787\n",
      "  Batch 890/910 - Loss: 0.0062\n",
      "  Batch 900/910 - Loss: 0.0114\n",
      "  Batch 910/910 - Loss: 0.0016\n",
      "Training Loss: 0.0386\n",
      "Validation Loss: 0.0808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.78      0.87      4151\n",
      "         1.0       0.41      0.91      0.57       701\n",
      "\n",
      "    accuracy                           0.80      4852\n",
      "   macro avg       0.70      0.84      0.72      4852\n",
      "weighted avg       0.90      0.80      0.83      4852\n",
      "\n",
      "Epoch 7/20\n",
      "  Batch 10/910 - Loss: 0.0087\n",
      "  Batch 20/910 - Loss: 0.0015\n",
      "  Batch 30/910 - Loss: 0.0107\n",
      "  Batch 40/910 - Loss: 0.0179\n",
      "  Batch 50/910 - Loss: 0.0041\n",
      "  Batch 60/910 - Loss: 0.0854\n",
      "  Batch 70/910 - Loss: 0.0152\n",
      "  Batch 80/910 - Loss: 0.0623\n",
      "  Batch 90/910 - Loss: 0.0102\n",
      "  Batch 100/910 - Loss: 0.0229\n",
      "  Batch 110/910 - Loss: 0.0145\n",
      "  Batch 120/910 - Loss: 0.0716\n",
      "  Batch 130/910 - Loss: 0.0491\n",
      "  Batch 140/910 - Loss: 0.0651\n",
      "  Batch 150/910 - Loss: 0.0174\n",
      "  Batch 160/910 - Loss: 0.0036\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 81\u001b[0m\n\u001b[0;32m     78\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     79\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 81\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m batch_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tanxe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanxe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau  \n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        encoding = self.tokenizer(\n",
    "            row['title'], row['content'], row['entities'], # Replace 'content' with 'article_content' if working with real data\n",
    "            add_special_tokens=True,\n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            max_length=self.max_length, \n",
    "            return_tensors='pt' #  return the output in the form of PyTorch tensors\n",
    "            )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(row['relevant'], dtype=torch.float), # for BCEWithLogitsLoss use float\n",
    "        }\n",
    "\n",
    "train_dataset = TextDataset(train_df, tokenizer, max_length=256)\n",
    "val_dataset = TextDataset(val_df, tokenizer, max_length=256)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_df['relevant']), y=train_df['relevant'])\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# load the XLNet model\n",
    "XLNet_model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=1)\n",
    "XLNet_model.to(device)\n",
    "\n",
    "# load from checkpoint\n",
    "# checkpoint = torch.load('best_XLNet_model_epoch_3_BCEWithLogitsLoss.pt')\n",
    "# XLNet_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Loss function and optimizer\n",
    "# loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
    "optimizer = AdamW(XLNet_model.parameters(), lr=2e-5)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.2, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "current_epoch = 1\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(current_epoch, num_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    XLNet_model.train() #switch to training mode\n",
    "    train_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad() # Clear old gradients\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "            'labels': batch['labels'].to(device),\n",
    "        }\n",
    "\n",
    "        outputs = XLNet_model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0 or batch_idx == len(train_dataloader) - 1:\n",
    "            print(f\"  Batch {batch_idx + 1}/{len(train_dataloader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(train_dataloader) # average training loss\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    XLNet_model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            inputs = {\n",
    "                'input_ids': batch['input_ids'].to(device),\n",
    "                'attention_mask': batch['attention_mask'].to(device),\n",
    "                'labels': batch['labels'].to(device),\n",
    "            }\n",
    "            outputs = XLNet_model(**inputs)\n",
    "            val_loss += outputs.loss.item()\n",
    "            logits = outputs.logits\n",
    "            preds = torch.sigmoid(logits).cpu().numpy() > 0.5  # threshold = 0.5 for  now\n",
    "            val_preds.extend(preds)           \n",
    "            val_labels.extend(inputs['labels'].cpu().numpy())\n",
    "            \n",
    "    val_loss /= len(val_dataloader) # average validation loss\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(classification_report(val_labels, val_preds))\n",
    "    # step the scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f\"Validation loss improved. Saving model.\")\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': XLNet_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_val_loss': best_val_loss\n",
    "    }, f\"best_XLNet_model_epoch_{epoch}_BCEWithLogitsLoss.pt\")\n",
    "\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted XLNet\n",
    "Only trained on the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau  \n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        encoding = self.tokenizer(\n",
    "            row['entities'], # Replace 'content' with 'article_content' if working with real data\n",
    "            add_special_tokens=True,\n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            max_length=self.max_length, \n",
    "            return_tensors='pt' #  return the output in the form of PyTorch tensors\n",
    "            )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(row['relevant'], dtype=torch.float), # for BCEWithLogitsLoss use float\n",
    "        }\n",
    "\n",
    "train_dataset = TextDataset(train_df, tokenizer, max_length=256)\n",
    "val_dataset = TextDataset(val_df, tokenizer, max_length=256)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_df['relevant']), y=train_df['relevant'])\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# load the XLNet model\n",
    "XLNet_model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=1)\n",
    "XLNet_model.to(device)\n",
    "\n",
    "# load from checkpoint\n",
    "# checkpoint = torch.load('best_XLNet_model_epoch_3_BCEWithLogitsLoss.pt')\n",
    "# XLNet_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Loss function and optimizer\n",
    "# loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
    "optimizer = AdamW(XLNet_model.parameters(), lr=2e-5)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.2, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "current_epoch = 1\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(current_epoch, num_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    XLNet_model.train() #switch to training mode\n",
    "    train_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad() # Clear old gradients\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "            'labels': batch['labels'].to(device),\n",
    "        }\n",
    "\n",
    "        outputs = XLNet_model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0 or batch_idx == len(train_dataloader) - 1:\n",
    "            print(f\"  Batch {batch_idx + 1}/{len(train_dataloader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(train_dataloader) # average training loss\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    XLNet_model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            inputs = {\n",
    "                'input_ids': batch['input_ids'].to(device),\n",
    "                'attention_mask': batch['attention_mask'].to(device),\n",
    "                'labels': batch['labels'].to(device),\n",
    "            }\n",
    "            outputs = XLNet_model(**inputs)\n",
    "            val_loss += outputs.loss.item()\n",
    "            logits = outputs.logits\n",
    "            preds = torch.sigmoid(logits).cpu().numpy() > 0.5  # threshold = 0.5 for  now\n",
    "            val_preds.extend(preds)           \n",
    "            val_labels.extend(inputs['labels'].cpu().numpy())\n",
    "            \n",
    "    val_loss /= len(val_dataloader) # average validation loss\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(classification_report(val_labels, val_preds))\n",
    "    # step the scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f\"Validation loss improved. Saving model.\")\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': XLNet_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_val_loss': best_val_loss\n",
    "    }, f\"best_XLNet_model_epoch_{epoch}_BCEWithLogitsLoss.pt\")\n",
    "\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "XLNet_model.eval()\n",
    "y_probs, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "            'labels': batch['labels'].to(device),\n",
    "        }\n",
    "        outputs = XLNet_model(**inputs)\n",
    "        val_loss += outputs.loss.item()\n",
    "\n",
    "        logits = outputs.logits\n",
    "        preds = torch.sigmoid(logits).cpu().numpy()\n",
    "        y_probs.extend(preds)\n",
    "        y_true.extend(inputs['labels'].cpu().numpy())\n",
    "\n",
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_probs)\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plt.plot(recall, precision, color='b', label=\"Precision-Recall curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# Compute F1 scores \n",
    "f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the performance with different threshold values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TextDataset(test_df, tokenizer, max_length=128)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
    "XLNet_model.eval()\n",
    "y_preds, y_true = [], []\n",
    "with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            inputs = {\n",
    "                'input_ids': batch['input_ids'].to(device),\n",
    "                'attention_mask': batch['attention_mask'].to(device),\n",
    "                'labels': batch['labels'].to(device),\n",
    "            }\n",
    "            outputs = XLNet_model(**inputs)\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.sigmoid(logits).cpu().numpy() > 0.55 # testing threshold = 0.65 for now\n",
    "            y_preds.extend(preds)\n",
    "            y_true.extend(inputs['labels'].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.94      0.93      4158\n",
      "         1.0       0.58      0.52      0.55       694\n",
      "\n",
      "    accuracy                           0.88      4852\n",
      "   macro avg       0.75      0.73      0.74      4852\n",
      "weighted avg       0.87      0.88      0.87      4852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
